{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "intro_cell"
   },
   "source": [
    "# Guide pour l'Appel √† une API Hugging Face pour la Segmentation d'Images\n",
    "\n",
    "Bienvenue ! Ce notebook a pour but de vous guider pas √† pas dans l'utilisation de l'API d'inf√©rence de Hugging Face pour effectuer de la segmentation d'images. La segmentation d'images consiste √† attribuer une √©tiquette (comme \"cheveux\", \"v√™tement\", \"arri√®re-plan\") √† chaque pixel d'une image.\n",
    "\n",
    "Nous allons :\n",
    "1. Comprendre ce qu'est une API et comment s'y connecter.\n",
    "2. Envoyer une image √† un mod√®le de segmentation h√©berg√© sur Hugging Face.\n",
    "3. R√©cup√©rer et interpr√©ter les r√©sultats.\n",
    "4. Visualiser les masques de segmentation.\n",
    "5. √âtendre cela pour traiter plusieurs images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imports_intro_cell"
   },
   "source": [
    "### 1. Configuration Initiale et Importations\n",
    "\n",
    "Nous commen√ßons par importer toutes les biblioth√®ques Python n√©cessaires pour le projet de segmentation d‚Äôimages.\n",
    "\n",
    "<small>\n",
    "\n",
    "```python\n",
    "# --- Imports standards ---\n",
    "import os           # interagir avec le syst√®me de fichiers (lister les images, cr√©er des dossiers, etc.)\n",
    "import time         # mesurer les temps de traitement\n",
    "import asyncio      # g√©rer les appels asynchrones (utile pour plusieurs images en parall√®le)\n",
    "import requests     # effectuer des requ√™tes HTTP vers des API\n",
    "\n",
    "# --- Imports tiers ---\n",
    "import numpy as np                             # manipulation des tableaux num√©riques (images comme tableaux de pixels)\n",
    "import torch                                    # tenseurs et mod√®les deep learning\n",
    "from PIL import Image                           # lecture, √©criture et manipulation des images\n",
    "from tqdm.notebook import tqdm                  # barre de progression interactive dans Jupyter Notebook\n",
    "import aiohttp                                   # requ√™tes HTTP asynchrones\n",
    "from transformers import AutoModelForSemanticSegmentation, AutoImageProcessor\n",
    "                                               # mod√®les pr√©-entra√Æn√©s pour la segmentation d‚Äôimages\n",
    "from dotenv import load_dotenv                  # charger des variables d'environnement depuis un fichier .env\n",
    "import matplotlib.pyplot as plt                 # affichage des images et des masques de segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports_code_cell"
   },
   "outputs": [],
   "source": [
    "# --- Imports standards ---\n",
    "import os\n",
    "import time\n",
    "import asyncio\n",
    "import requests\n",
    "\n",
    "# --- Imports tiers ---\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import aiohttp\n",
    "from transformers import AutoModelForSemanticSegmentation, AutoImageProcessor\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# Pause (seconds) entre appels API pour √™tre courtois et √©viter le rate limiting\n",
    "PAUSE_BETWEEN_CALLS = 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config_vars_intro_cell"
   },
   "source": [
    "### Variables de Configuration\n",
    "\n",
    "Nous devons d√©finir quelques variables :\n",
    "- `images_dir`: Le chemin vers le dossier contenant vos images. **Assurez-vous de modifier ce chemin si n√©cessaire.**\n",
    "- `predicted_masks_dir`: Le chemin vers le dossier contenant les masques pr√©dits. **Assurez-vous de modifier ce chemin si n√©cessaire.**\n",
    "- `ground_truth_masks_dir`: Le chemin vers le dossier o√π les masques de v√©rit√© terrain sont sauvegard√©s. **Assurez-vous de modifier ce chemin si n√©cessaire.**\n",
    "\n",
    "‚ö†Ô∏è **IMPORTANT :** Merci d'utiliser le m√™me nommage pour vos images et vos masques (image_01 -> mask_01)\n",
    "\n",
    "- `max_images`: Le nombre maximum d'images √† traiter (pour ne pas surcharger l'API ou attendre trop longtemps).\n",
    "- `api_token`: Votre jeton d'API Hugging Face. **IMPORTANT : Gardez ce jeton secret !**\n",
    "\n",
    "**Comment obtenir un token API Hugging Face ?**\n",
    "1. Cr√©ez un compte sur [huggingface.co](https://huggingface.co/).\n",
    "2. Allez dans votre profil -> Settings -> Access Tokens.\n",
    "3. Cr√©ez un nouveau token (par exemple, avec le r√¥le \"read\").\n",
    "4. Copiez ce token ici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config_vars_code_cell"
   },
   "outputs": [],
   "source": [
    "# Configuration pour le projet Fashion Trend Intelligence\n",
    "# Charger les variables d'environnement depuis le fichier .env\n",
    "load_dotenv()\n",
    "\n",
    "# Utiliser la variable d'environnement pour le token API (plus s√©curis√©)\n",
    "api_token = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "\n",
    "# Mise √† jour des chemins pour la structure de votre projet\n",
    "images_dir = \"../assets/images\"  # Images stock√©es dans le dossier assets\n",
    "predicted_masks_dir = \"../assets/predicted_masks\"  # Masques de v√©rit√© terrain\n",
    "ground_truth_masks_dir = \"../assets/ground_truth_masks\"  # Masques de v√©rit√© terrain\n",
    "max_images = 1  # Commen√ßons avec peu d'images\n",
    "\n",
    "# Cr√©er le dossier assets s'il n'existe pas\n",
    "if not os.path.exists(images_dir):\n",
    "    os.makedirs(images_dir)\n",
    "    print(f\"‚úÖ Dossier images '{images_dir}' cr√©√©. Veuillez y ajouter des images.\")\n",
    "else:\n",
    "    print(f\"‚úÖ Dossier images '{images_dir}' existant.\")\n",
    "\n",
    "if not os.path.exists(predicted_masks_dir):\n",
    "    os.makedirs(predicted_masks_dir)\n",
    "    print(f\"‚úÖ Dossier masques '{predicted_masks_dir}' cr√©√©. Veuillez y ajouter des masques.\")\n",
    "else:\n",
    "    print(f\"‚úÖ Dossier masques '{predicted_masks_dir}' existant.\")\n",
    "\n",
    "if not os.path.exists(ground_truth_masks_dir):\n",
    "    os.makedirs(ground_truth_masks_dir)\n",
    "    print(f\"‚úÖ Dossier masques de v√©rit√© terrain '{ground_truth_masks_dir}' cr√©√©. Veuillez y ajouter des masques.\")\n",
    "else:\n",
    "    print(f\"‚úÖ Dossier masques de v√©rit√© terrain '{ground_truth_masks_dir}' existant.\")\n",
    "\n",
    "if not api_token or api_token == \"your_huggingface_api_key_here\":\n",
    "    print(\"\\n‚ö†Ô∏è  ATTENTION : Veuillez configurer votre HUGGINGFACE_API_KEY dans le fichier .env\")\n",
    "    print(\"üìñ Obtenez votre token depuis : https://huggingface.co/settings/tokens\")\n",
    "else:\n",
    "    print(f\"‚úÖ Token API charg√© avec succ√®s (se terminant par : ...{api_token[-8:]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "api_understanding_cell"
   },
   "source": [
    "## 2. Comprendre l'API d'Inf√©rence Hugging Face\n",
    "\n",
    "L'API d'inf√©rence permet d'utiliser des mod√®les h√©berg√©s sur Hugging Face sans avoir √† les t√©l√©charger ou √† g√©rer l'infrastructure.\n",
    "\n",
    "- **Mod√®le utilis√©** : Nous allons utiliser le mod√®le `sayeed99/segformer_b3_clothes`, sp√©cialis√© dans la segmentation de v√™tements et de parties du corps.\n",
    "- **URL de l'API** : L'URL pour un mod√®le est g√©n√©ralement `https://api-inference.huggingface.co/models/NOM_DU_MODELE`.\n",
    "- **Headers (En-t√™tes)** : Pour s'authentifier et sp√©cifier le type de contenu, nous envoyons des en-t√™tes avec notre requ√™te.\n",
    "    - `Authorization`: Contient notre token API (pr√©c√©d√© de `Bearer `).\n",
    "    - `Content-Type`: Indique que nous envoyons une image au format JPEG (ou PNG selon le cas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "api_setup_code_cell"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "API_URL = \"https://router.huggingface.co/hf-inference/models/sayeed99/segformer_b3_clothes\"  # Remplacez ... par le bon endpoint.\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_token}\"\n",
    "    # Le \"Content-Type\" sera ajout√© dynamiquement lors de l'envoi de l'image\n",
    "}\n",
    "\n",
    "# Import des modules utilitaires pour les images et les connexions\n",
    "import oc_p2_fashion_trend_intelligence.utils.image_utils as image_utils\n",
    "import oc_p2_fashion_trend_intelligence.utils.connection_utils as connection_utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "helper_functions_intro_cell"
   },
   "source": [
    "## 3. Configuration et Validation des Images\n",
    "\n",
    "Cette section regroupe **toutes les constantes configurables** du notebook pour faciliter la personnalisation :\n",
    "\n",
    "**üìù Configuration modifiable :**\n",
    "- `ALLOWED_EXTENSIONS`: Extensions d'images support√©es \n",
    "- `CLASS_MAPPING`: Classes sp√©cifiques au mod√®le `segformer_b3_clothes`\n",
    "- `PALETTE`: Couleurs pour visualiser les masques de segmentation\n",
    "\n",
    "**üîç Validation automatique :**\n",
    "- Listing des images dans le dossier d√©fini\n",
    "- Validation du format et de la taille des images\n",
    "\n",
    "\n",
    "üí° **Astuce** : Modifiez `ALLOWED_EXTENSIONS` si vous voulez supporter d'autres formats d'image !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "helper_functions_code_cell"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION DU NOTEBOOK - MODIFIEZ SELON VOS BESOINS\n",
    "# =============================================================================\n",
    "\n",
    "# Extensions d'images support√©es\n",
    "ALLOWED_EXTENSIONS = (\".png\", \".jpg\", \".jpeg\", \".bmp\", \".webp\")\n",
    "\n",
    "# Configuration sp√©cifique au mod√®le segformer_b3_clothes\n",
    "CLASS_MAPPING = {\n",
    "    \"Background\": 0,\n",
    "    \"Hat\": 1,\n",
    "    \"Hair\": 2,\n",
    "    \"Sunglasses\": 3,\n",
    "    \"Upper-clothes\": 4,\n",
    "    \"Skirt\": 5,\n",
    "    \"Pants\": 6,\n",
    "    \"Dress\": 7,\n",
    "    \"Belt\": 8,\n",
    "    \"Left-shoe\": 9,\n",
    "    \"Right-shoe\": 10,\n",
    "    \"Face\": 11,\n",
    "    \"Left-leg\": 12,\n",
    "    \"Right-leg\": 13,\n",
    "    \"Left-arm\": 14,\n",
    "    \"Right-arm\": 15,\n",
    "    \"Bag\": 16,\n",
    "    \"Scarf\": 17\n",
    "}\n",
    "\n",
    "# Palette de couleurs\n",
    "# Les couleurs proches pour bras, jambes et chaussures permettent de reconna√Ætre la sym√©trie.\n",
    "# Les accessoires (Hat, Bag, Scarf) ont des teintes distinctes pour les diff√©rencier facilement.\n",
    "# Fond noir (Background) pour faire ressortir les v√™tements.\n",
    "# Les couleurs vives aident √† visualiser clairement les masques sur l‚Äôimage.\n",
    "\n",
    "PALETTE = {\n",
    "    0:  [0, 0, 0],    # Background = noir\n",
    "    1:  [255, 128, 0],      # Hat = orange\n",
    "    2:  [255, 192, 203],    # Hair = rose clair\n",
    "    3:  [0, 255, 255],      # Sunglasses = cyan\n",
    "    4:  [255, 0, 0],        # Upper-clothes = rouge\n",
    "    5:  [255, 165, 0],      # Skirt = orange clair\n",
    "    6:  [0, 128, 0],        # Pants = vert fonc√©\n",
    "    7:  [128, 0, 128],      # Dress = violet\n",
    "    8:  [128, 64, 0],       # Belt = marron\n",
    "    9:  [0, 0, 255],        # Left-shoe = bleu\n",
    "    10: [0, 0, 200],        # Right-shoe = bleu plus fonc√©\n",
    "    11: [255, 224, 189],    # Face = couleur peau claire\n",
    "    12: [0, 255, 0],        # Left-leg = vert clair\n",
    "    13: [0, 200, 0],        # Right-leg = vert fonc√©\n",
    "    14: [255, 255, 0],      # Left-arm = jaune\n",
    "    15: [200, 200, 0],      # Right-arm = jaune fonc√©\n",
    "    16: [128, 0, 0],        # Bag = rouge fonc√©\n",
    "    17: [0, 128, 128]       # Scarf = teal / bleu-vert\n",
    "}\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# LISTING ET VALIDATION DES IMAGES\n",
    "# =============================================================================\n",
    "\n",
    "# Lister les chemins des images √† traiter\n",
    "image_paths = [\n",
    "    os.path.join(images_dir, filename) \n",
    "    for filename in os.listdir(images_dir) \n",
    "    if filename.endswith(ALLOWED_EXTENSIONS)\n",
    "]\n",
    "# Tri des images par nom du fichier, identifiant le _xx apr√®s image_\n",
    "# pour traiter les images dans l'ordre (image_01, image_02, ..., image_10, image_11, ...)\n",
    "# et non pas (image_1, image_10, image_11, image_2, ...)\n",
    "image_paths.sort(\n",
    "    key=lambda x: os.path.basename(x).split(\"_\")[1],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "# Valider les images (format, taille, etc.)\n",
    "valid_images = [img_path for img_path in image_paths if image_utils.validate_single_image(img_path, max_size=(1024, 1024))]\n",
    "\n",
    "if not valid_images:\n",
    "    print(f\"Aucune image valide trouv√©e dans '{images_dir}'. Veuillez y ajouter des images.\")\n",
    "else:\n",
    "    print(f\"{len(valid_images)} image(s) valide(s) sur {len(image_paths)} √† traiter.\")\n",
    "    \n",
    "# Les fonctions utilitaires (get_image_dimensions, decode_base64_mask, create_masks) \n",
    "# sont maintenant disponibles via l'import depuis image_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "single_image_intro_cell"
   },
   "source": [
    "## 4. Segmentation d'une Seule Image\n",
    "\n",
    "Avant de traiter toutes les images, concentrons-nous sur une seule pour bien comprendre le processus.\n",
    "\n",
    "‚ö†Ô∏è Le service utilis√© sayeed99/segformer_b3_clothes ne semble pas stable et peut r√©guli√®rement entr√¢iner des timeouts. Si vous rencontrez des erreurs, RDV √† l'Annexe 3   pour une version locale.\n",
    "\n",
    "√âtapes :\n",
    "1.  Choisir une image.\n",
    "2.  Ouvrir l'image en mode binaire (`\"rb\"`) et lire son contenu (`data`).\n",
    "3.  D√©terminer le `Content-Type` (par exemple, `\"image/jpeg\"` ou `\"image/png\"`).\n",
    "4.  Envoyer la requ√™te POST √† l'API avec `requests.post()` en passant l'URL, les headers et les donn√©es.\n",
    "5.  V√©rifier le code de statut de la r√©ponse. Une erreur sera lev√©e si le code n'est pas 2xx (succ√®s) gr√¢ce √† `response.raise_for_status()`.\n",
    "6.  Convertir la r√©ponse JSON en un dictionnaire Python avec `response.json()`.\n",
    "7.  Utiliser nos fonctions `get_image_dimensions` et `create_masks` pour obtenir le masque final.\n",
    "8.  Sauvegarder le masque dans le dossier d√©fini.\n",
    "9.  Afficher l'image originale et le masque segment√©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "single_image_code_cell"
   },
   "outputs": [],
   "source": [
    "if image_paths:\n",
    "    single_image_path = image_paths[3]\n",
    "    print(f\"Traitement de l'image : {single_image_path}\")\n",
    "\n",
    "    # Lecture du fichier\n",
    "    try:\n",
    "        with open(single_image_path, \"rb\") as image_file:\n",
    "            image_data = image_file.read()\n",
    "    except OSError as e:\n",
    "        print(f\"üìÇ Erreur lecture fichier : {e}\")\n",
    "        raise RuntimeError(\"Arr√™t de la cellule car fichier non lisible\")\n",
    "\n",
    "    # D√©terminer dynamiquement le content-type\n",
    "    ext = os.path.splitext(single_image_path)[1].lower()\n",
    "    headers[\"Content-Type\"] = f\"image/{ext[1:]}\"\n",
    "\n",
    "    # Appel API\n",
    "    response = connection_utils.post_with_retries(API_URL, headers=headers, data=image_data)\n",
    "    if response is None:\n",
    "        raise RuntimeError(\"‚ùå Impossible de segmenter l'image ‚Üí arr√™t de la cellule\")\n",
    "\n",
    "    print(\"‚úÖ Segmentation r√©ussie !\")\n",
    "\n",
    "    # Traitement du r√©sultat\n",
    "    try:\n",
    "        segmentation_result = response.json()\n",
    "        width, height = image_utils.get_image_dimensions(single_image_path)\n",
    "        mask = image_utils.create_masks(segmentation_result, width, height, CLASS_MAPPING)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erreur lors du traitement de la segmentation : {e}\")\n",
    "        raise RuntimeError(\"Arr√™t de la cellule suite √† une erreur dans le masque\")\n",
    "\n",
    "    # Sauvegarde du masque\n",
    "    mask_save_path = os.path.join(\n",
    "        predicted_masks_dir, os.path.basename(single_image_path).replace('image', 'mask')\n",
    "    )\n",
    "    Image.fromarray(mask).save(mask_save_path)\n",
    "    print(f\"üñºÔ∏è Masque sauvegard√© : {mask_save_path}\")\n",
    "\n",
    "    # Affichage\n",
    "    image_utils.show_image_and_masks(\n",
    "        single_image_path,\n",
    "        ground_truth_masks_dir,\n",
    "        CLASS_MAPPING,\n",
    "        PALETTE,\n",
    "        predicted_masks_dir, None\n",
    "    )\n",
    "\n",
    "    # Evaluation simple si masque de v√©rit√© terrain disponible\n",
    "    ground_truth_mask_path = image_utils.search_for_ground_truth_mask_path(\n",
    "        single_image_path, ground_truth_masks_dir\n",
    "    )\n",
    "    if ground_truth_mask_path:\n",
    "        print(image_utils.eval_segmentation_simple(ground_truth_mask_path, mask_save_path, CLASS_MAPPING, PALETTE))\n",
    "\n",
    "else:\n",
    "    print(\n",
    "        \"Aucune image √† traiter. V√©rifiez la configuration de 'images_dir' et 'max_images'.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch_intro_cell"
   },
   "source": [
    "## 5. Segmentation de Plusieurs Images (Batch)\n",
    "\n",
    "Maintenant que nous savons comment traiter une image, nous pouvons cr√©er une fonction pour en traiter plusieurs.\n",
    "Cette fonction va boucler sur la liste `image_paths` et appliquer la logique de segmentation √† chaque image.\n",
    "Nous utiliserons `tqdm` pour avoir une barre de progression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "batch_code_cell"
   },
   "outputs": [],
   "source": [
    "def segment_images_batch(list_of_image_paths):\n",
    "    \"\"\"\n",
    "    Segmente une liste d'images en utilisant l'API Hugging Face.\n",
    "\n",
    "    Args:\n",
    "        list_of_image_paths (list): Liste des chemins vers les images.\n",
    "\n",
    "    Returns:\n",
    "        list: Liste des masques de segmentation (tableaux NumPy).\n",
    "              Contient None si une image n'a pas pu √™tre trait√©e.\n",
    "    \"\"\"\n",
    "    batch_segmentations = []\n",
    "\n",
    "    # N'oubliez pas de mettre une pause entre chaque appel API !\n",
    "    for img_path in tqdm(list_of_image_paths, desc=\"Segmentation des images en batch\"):\n",
    "        mask = None\n",
    "        try:\n",
    "            # Lecture fichier image\n",
    "            with open(img_path, \"rb\") as image_file:\n",
    "                image_data = image_file.read()\n",
    "        except OSError as e:\n",
    "            print(f\"üìÇ Erreur lecture fichier {img_path} : {e}\")\n",
    "            batch_segmentations.append(None)\n",
    "            continue  # passe directement √† l‚Äôimage suivante\n",
    "\n",
    "        headers[\"Content-Type\"] = \"image/png\"\n",
    "        response = connection_utils.post_with_retries(API_URL, headers=headers, data=image_data)\n",
    "\n",
    "        if response is not None:\n",
    "            try:\n",
    "                segmentation_result = response.json()\n",
    "                width, height = image_utils.get_image_dimensions(img_path)\n",
    "                mask = image_utils.create_masks(segmentation_result, width, height, CLASS_MAPPING)\n",
    "                # Sauvegarde du masque\n",
    "                mask_save_path = os.path.join(\n",
    "                    predicted_masks_dir, os.path.basename(img_path).replace('image', 'mask')\n",
    "                )\n",
    "                Image.fromarray(mask).save(mask_save_path)\n",
    "                print(f\"üñºÔ∏è Masque sauvegard√© : {mask_save_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Erreur lors du traitement de {img_path} : {e}\")\n",
    "                mask = None\n",
    "        else:\n",
    "            print(f\"‚ùå API n'a pas renvoy√© de r√©sultat pour {img_path}\")\n",
    "\n",
    "        batch_segmentations.append(mask)\n",
    "\n",
    "        # Pause entre les appels API\n",
    "        time.sleep(PAUSE_BETWEEN_CALLS)\n",
    "\n",
    "    return batch_segmentations\n",
    "\n",
    "# Appeler la fonction pour segmenter les images list√©es dans image_paths\n",
    "if image_paths:\n",
    "    print(f\"\\nTraitement de {len(image_paths)} image(s) en batch...\")\n",
    "    batch_seg_results = segment_images_batch(image_paths)\n",
    "    print(\"Traitement en batch termin√©.\")\n",
    "else:\n",
    "    batch_seg_results = []\n",
    "    print(\"Aucune image √† traiter en batch.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "display_batch_intro_cell"
   },
   "source": [
    "## 6. Affichage des R√©sultats\n",
    "\n",
    "Nous allons maintenant cr√©er une fonction pour afficher le r√©sultat des traitements : \n",
    "- les images originales,\n",
    "- leur masque pr√©dit,\n",
    "- le masque de v√©rit√© terrain,\n",
    "- des m√©triques d'√©valuation (IoU, Accuracy).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "display_batch_code_cell"
   },
   "outputs": [],
   "source": [
    "def display_results(original_image_paths):\n",
    "    \"\"\"\n",
    "    Affiche les images originales et leurs masques segment√©s √† partir des chemins fournis.\n",
    "\n",
    "    Args:\n",
    "        original_image_paths (list): Liste des chemins des images originales.\n",
    "    \"\"\"\n",
    "    num_images = len(original_image_paths)\n",
    "    print(f\"\\nAffichage des r√©sultats des {num_images} images...\")\n",
    "\n",
    "    image_with_best_accuracy = None\n",
    "    best_accuracy = 0.0\n",
    "    image_with_worst_accuracy = None  # --- IGNORE ---\n",
    "    worst_accuracy = 1.0\n",
    "\n",
    "    image_with_best_mIoU = None\n",
    "    best_mIoU = 0.0\n",
    "    image_with_worst_mIoU = None  # --- IGNORE ---\n",
    "    worst_mIoU = 1.0\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Affichage de l'image initiale, du masque pr√©dit et du masque de v√©rit√© terrain si disponible\n",
    "        image_utils.show_image_and_masks(\n",
    "            original_image_paths[i],\n",
    "            ground_truth_masks_dir,\n",
    "            CLASS_MAPPING,\n",
    "            PALETTE,\n",
    "            predicted_masks_dir, None\n",
    "        )\n",
    "\n",
    "        # Evaluation simple si masque de v√©rit√© terrain disponible\n",
    "        ground_truth_mask_path = image_utils.search_for_ground_truth_mask_path(original_image_paths[i], ground_truth_masks_dir)\n",
    "        if ground_truth_mask_path is not None:\n",
    "            result = image_utils.eval_segmentation_simple(\n",
    "                ground_truth_mask_path,\n",
    "                os.path.join(predicted_masks_dir, os.path.basename(original_image_paths[i]).replace('image', 'mask')),\n",
    "                CLASS_MAPPING,\n",
    "                PALETTE\n",
    "            )\n",
    "            if result[\"accuracy\"] > best_accuracy:\n",
    "                best_accuracy = result[\"accuracy\"]\n",
    "                image_with_best_accuracy = original_image_paths[i]\n",
    "            if result[\"accuracy\"] < worst_accuracy:  # --- IGNORE ---\n",
    "                worst_accuracy = result[\"accuracy\"]\n",
    "                image_with_worst_accuracy = original_image_paths[i]\n",
    "            if result[\"mIoU\"] > best_mIoU:\n",
    "                best_mIoU = result[\"mIoU\"]\n",
    "                image_with_best_mIoU = original_image_paths[i]\n",
    "            if result[\"mIoU\"] < worst_mIoU:  # --- IGNORE ---\n",
    "                worst_mIoU = result[\"mIoU\"]\n",
    "                image_with_worst_mIoU = original_image_paths[i]\n",
    "        else:\n",
    "            print(\"Aucun masque de v√©rit√© terrain trouv√© pour cette image.\")\n",
    "    if image_with_best_accuracy:\n",
    "        print(f\"\\nL'image avec la meilleure pr√©cision est : {image_with_best_accuracy} avec une pr√©cision de {best_accuracy:.4f}\")\n",
    "    if image_with_best_mIoU:\n",
    "        print(f\"\\nL'image avec le meilleur mIoU est : {image_with_best_mIoU} avec un mIoU de {best_mIoU:.4f}\")\n",
    "    if image_with_worst_accuracy:  # --- IGNORE ---\n",
    "        print(f\"\\nL'image avec la pire pr√©cision est : {image_with_worst_accuracy} avec une pr√©cision de {worst_accuracy:.4f}\")\n",
    "    if image_with_worst_mIoU:  # --- IGNORE ---\n",
    "        print(f\"\\nL'image avec le pire mIoU est : {image_with_worst_mIoU} avec un mIoU de {worst_mIoU:.4f}\")\n",
    "\n",
    "# Afficher les r√©sultats du batch\n",
    "print(\"\\nAffichage des r√©sultats du batch...\", image_paths)\n",
    "display_results(image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conclusion_cell"
   },
   "source": [
    "## Conclusion et Prochaines √âtapes\n",
    "\n",
    "F√©licitations ! Vous avez appris √† :\n",
    "- Configurer les appels √† l'API d'inf√©rence Hugging Face.\n",
    "- Envoyer des images pour la segmentation.\n",
    "- Interpr√©ter les r√©sultats (avec l'aide des fonctions fournies).\n",
    "- Visualiser les segmentations.\n",
    "\n",
    "Pistes d'am√©lioration ou d'exploration :\n",
    "- **Gestion d'erreurs plus fine** : Impl√©menter des tentatives multiples (retry) en cas d'√©chec de l'API (par exemple, si le mod√®le est en cours de chargement).\n",
    "- **Appels asynchrones** : Pour un grand nombre d'images, des appels asynchrones (avec `asyncio` et `aiohttp`) seraient beaucoup plus rapides.\n",
    "- **Autres mod√®les** : Explorer d'autres mod√®les de segmentation ou d'autres t√¢ches sur Hugging Face Hub.\n",
    "\n",
    "N'h√©sitez pas √† modifier le code, √† tester avec vos propres images et √† explorer davantage !\n",
    "\n",
    "**_Note_** : Si vous aimez ce mod√®le, n'h√©sitez pas √† le [t√©l√©charger](https://huggingface.co/sayeed99/segformer_b3_clothes) et jouer avec directement sur votre machine !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annexe 1. Evaluation de deux masques\n",
    "\n",
    "Nous allons maintenant √©valuer la qualit√© d'un masque de segmentation pr√©dite par rapport √† un masque de v√©rit√© terrain, en utilisant des m√©triques telles que l'Intersection over Union (IoU) et la pr√©cision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TV_ctytI7EQn"
   },
   "outputs": [],
   "source": [
    "# TEST : Evaluation de deux masques\n",
    "# Recherche du masque de v√©rit√© terrain pour une image donn√©e\n",
    "ground_truth_mask_path = image_utils.search_for_ground_truth_mask_path(\n",
    "    \"../assets/ground_truth_masks/image_24.png\", ground_truth_masks_dir\n",
    ")\n",
    "if ground_truth_mask_path:\n",
    "\tprint(image_utils.eval_segmentation_simple(ground_truth_mask_path, \"../assets/predicted_masks/mask_24.png\", CLASS_MAPPING, PALETTE))\n",
    "else :\n",
    "\tprint(\"Aucun masque de v√©rit√© terrain trouv√© pour cette image.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annexe 2 : üïû Comparaison entre des requ√™tes synchrones et asynchrones (request vs aiohttp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essai / comparaison entre request et asyncio / aiohttp\n",
    "\n",
    "# ------------------ VERSION SYNCHRONE ------------------\n",
    "def segment_images_sync(image_paths, headers=headers, timeout=30):\n",
    "    results = []\n",
    "    for img_path in image_paths:\n",
    "        with open(img_path, \"rb\") as f:\n",
    "            image_data = f.read()\n",
    "        ext = os.path.splitext(img_path)[1].lower()\n",
    "        headers[\"Content-Type\"] = f\"image/{ext[1:]}\"\n",
    "        try:\n",
    "            resp = requests.post(\n",
    "                API_URL, headers=headers, data=image_data, timeout=timeout\n",
    "            )\n",
    "            results.append((img_path, resp.json() if resp.status_code == 200 else None))\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"üåê Erreur r√©seau pour {img_path} : {e}\")\n",
    "            results.append((img_path, None))\n",
    "    return results\n",
    "\n",
    "\n",
    "# ------------------ VERSION ASYNCHRONE ------------------\n",
    "async def segment_images_async(image_paths, headers=headers):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for img_path in image_paths:\n",
    "            with open(img_path, \"rb\") as f:\n",
    "                image_data = f.read()\n",
    "            ext = os.path.splitext(img_path)[1].lower()\n",
    "            headers[\"Content-Type\"] = f\"image/{ext[1:]}\"\n",
    "            tasks.append(session.post(API_URL, headers=headers, data=image_data))\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "        results = []\n",
    "        for img_path, resp in zip(image_paths, responses):\n",
    "            results.append((img_path, await resp.json()))\n",
    "        return results\n",
    "\n",
    "\n",
    "# ------------------ BENCHMARK ------------------\n",
    "print(\"‚è±Ô∏è Benchmark SYNCHRONE\")\n",
    "start = time.time()\n",
    "results_sync = segment_images_sync(image_paths, headers=headers)\n",
    "sync_time = time.time() - start\n",
    "print(f\"Temps total synchrone : {sync_time:.2f}s\\n\")\n",
    "\n",
    "print(\"‚è±Ô∏è Benchmark ASYNCHRONE\")\n",
    "start = time.time()\n",
    "results_async = await segment_images_async(image_paths, headers=headers)\n",
    "async_time = time.time() - start\n",
    "print(f\"Temps total asynchrone : {async_time:.2f}s\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Annexe 3 : ‚ö†Ô∏è En cas de non disponibilit√© d'Hugging Face API, vous pouvez utiliser le mod√®le en local avec la biblioth√®que `transformers` de Hugging Face.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test du mod√®le en local\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# 1. Charger mod√®le + processeur (une seule fois, mis en cache local ensuite)\n",
    "model_name = \"sayeed99/segformer_b3_clothes\"\n",
    "model = AutoModelForSemanticSegmentation.from_pretrained(model_name)\n",
    "processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "# Liste des chemins d‚Äôimages\n",
    "print(f\"Nombre d'images trouv√©es : {len(image_paths)}\")\n",
    "\n",
    "# Boucle sur toutes les images\n",
    "start_time = time.time()\n",
    "for single_image_path in image_paths:\n",
    "    print(f\"Traitement de l'image : {single_image_path}\")\n",
    "\n",
    "    try:\n",
    "        image = Image.open(single_image_path)\n",
    "    except OSError as e:\n",
    "        print(f\"üìÇ Erreur lecture fichier : {e}\")\n",
    "        continue  # passe √† l‚Äôimage suivante\n",
    "\n",
    "    # Pr√©traitement\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # Inf√©rence\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Post-traitement\n",
    "    logits = outputs.logits\n",
    "    upsampled_logits = torch.nn.functional.interpolate(\n",
    "        logits, size=image.size[::-1], mode=\"bilinear\", align_corners=False  # (H, W)\n",
    "    )\n",
    "    pred_seg = upsampled_logits.argmax(dim=1)[0].cpu().numpy().astype(np.uint8)\n",
    "\n",
    "    image_utils.show_image_and_masks(\n",
    "        single_image_path, ground_truth_masks_dir, CLASS_MAPPING, PALETTE, None, pred_seg\n",
    "    )\n",
    "    ground_truth_mask_path = image_utils.search_for_ground_truth_mask_path(single_image_path, ground_truth_masks_dir)\n",
    "    if ground_truth_mask_path is not None:\n",
    "        image_utils.eval_segmentation_simple(\n",
    "            ground_truth_mask_path,\n",
    "            os.path.join(\n",
    "\t\t\t\tpredicted_masks_dir,\n",
    "\t\t\t\tos.path.basename(single_image_path).replace(\"image\", \"mask\"),\n",
    "\t\t\t),\n",
    "            CLASS_MAPPING,\n",
    "            PALETTE\n",
    "        )\n",
    "    else:\n",
    "        print(\"Aucun masque de v√©rit√© terrain trouv√© pour cette image.\")\n",
    "\n",
    "    # Sauvegarde masque\n",
    "    mask_save_path = os.path.join(\n",
    "        predicted_masks_dir,\n",
    "        os.path.basename(single_image_path).replace(\"image\", \"mask\"),\n",
    "    )\n",
    "    Image.fromarray(pred_seg).save(mask_save_path)\n",
    "    print(f\"üñºÔ∏è Masque sauvegard√© : {mask_save_path}\")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"‚è±Ô∏è Temps total pour {len(image_paths)} images : {elapsed_time:.2f} secondes\")\n",
    "print(f\"‚è±Ô∏è Temps moyen par image : {elapsed_time / len(image_paths):.2f} secondes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "oc-p2-fashion-trend-intelligence-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
